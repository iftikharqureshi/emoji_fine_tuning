{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emoji-Style Chatbot Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "I’m about to take you on a quick, hands-on tour of fine-tuning an OpenAI model using the official Python SDK. Think of this notebook as my little lab where I load a training file, start a job, keep an eye on its progress, and then give the customized model a quick test drive to see how it behaves on real prompts.\n",
    "\n",
    "In this very first cell I set the stage. I import the SDK client along with a few helpers for reading environment variables, pausing between status checks, and capturing secrets without printing them on screen. Then I name the essentials that guide the entire run: the path to my `.jsonl` training data, the base model I plan to adapt, a short suffix that will help me spot the resulting model later, and the number of epochs that control how many passes the trainer makes over my data. I run this once to pin down the configuration so the rest of the notebook can flow smoothly from upload to job creation to monitoring and finally to a quick sanity check of the tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from getpass import getpass\n",
    "\n",
    "# Training data file\n",
    "TRAINING_FILE_PATH = \"data/emoji_ft_train.jsonl\"\n",
    "\n",
    "# Model for fine-tuning\n",
    "BASE_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "# Custom suffix to model name\n",
    "MODEL_SUFFIX = \"emoji-v1\"\n",
    "\n",
    "# Set the number of training epochs\n",
    "N_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize OpenAI Client\n",
    "Before I can talk to the API, I need my credentials. I first check the environment for `OPENAI_API_KEY`, and if it is missing I quietly prompt for it with `getpass` so the secret never appears in the notebook output. With the key in hand, I create an `OpenAI` client that all later steps will reuse for uploads, job creation, and status checks. The short print line is my quick confirmation that authentication is set and the SDK is ready to make requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client initialized.\n"
     ]
    }
   ],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    api_key = getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "print(\"OpenAI client initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Training File\n",
    "Now I hand the API my training data. I open the `.jsonl` file in binary mode and send it to the Files endpoint with the purpose set to fine-tune, which lets the service know this upload is destined for a training job. If everything goes well, I print a friendly confirmation along with the server-assigned file ID and the original filename so I can reference or audit it later. If the path is wrong or the file is missing, the `FileNotFoundError` branch gives me a clear message that points straight to the problematic location, making it easy to fix the path and rerun the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file uploaded successfully!\n",
      "   ID: file-NoPS4m5fKQPo7ry41HCsQJ\n",
      "   Name: emoji_ft_train.jsonl\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(TRAINING_FILE_PATH, \"rb\") as f:\n",
    "        training_file = client.files.create(file=f, purpose=\"fine-tune\")\n",
    "    print(\"Training file uploaded successfully!\")\n",
    "    print(f\"   ID: {training_file.id}\")\n",
    "    print(f\"   Name: {training_file.filename}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Training file not found at '{TRAINING_FILE_PATH}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Fine-Tuning Job\n",
    "With the training file safely uploaded, I kick off the actual fine-tuning run by creating a job on the service. I pass the server’s file ID along with the base model I want to adapt, set the number of epochs through the hyperparameters, and add a short suffix so the resulting model name is easy to recognize later. The API returns a job object, so I stash its ID for the monitoring step and print a quick snapshot of the job ID and its initial status as a breadcrumb in the notebook output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job created!\n",
      "   Job ID: ftjob-m6dEhtrjGqtAFuuKWPuvEkFA\n",
      "   Status: validating_files\n"
     ]
    }
   ],
   "source": [
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    model=BASE_MODEL,\n",
    "    hyperparameters={\"n_epochs\": N_EPOCHS},\n",
    "    suffix=MODEL_SUFFIX,\n",
    ")\n",
    "\n",
    "job_id = job.id\n",
    "\n",
    "print(\"Fine-tuning job created!\")\n",
    "print(f\"   Job ID: {job_id}\")\n",
    "print(f\"   Status: {job.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor Job Progress\n",
    "Now I settle in to watch the run. I set a polling interval and start a simple timer so each status line shows an elapsed clock in minutes and seconds, which makes progress feel tangible. In the loop I retrieve the job, read its current status, and print a timestamped update. If the service reports that the job has succeeded, failed, or been cancelled, I exit the loop and announce the final state. After that I fetch the definitive job record and try to grab the `fine_tuned_model` identifier. If it is present, I print the new model name so I can use it in the next step; if not, I dump the job details to help me diagnose what went wrong before I try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring job ftjob-m6dEhtrjGqtAFuuKWPuvEkFA. Polling every 30 seconds...\n",
      "[00:00] Job Status: validating_files\n",
      "[00:30] Job Status: validating_files\n",
      "[01:01] Job Status: validating_files\n",
      "[01:31] Job Status: running\n",
      "[02:01] Job Status: running\n",
      "[02:31] Job Status: running\n",
      "[03:01] Job Status: running\n",
      "[03:32] Job Status: running\n",
      "[04:02] Job Status: running\n",
      "[04:32] Job Status: running\n",
      "[05:02] Job Status: running\n",
      "[05:32] Job Status: running\n",
      "[06:03] Job Status: running\n",
      "[06:33] Job Status: running\n",
      "[07:03] Job Status: running\n",
      "[07:33] Job Status: running\n",
      "[08:03] Job Status: running\n",
      "[08:34] Job Status: running\n",
      "[09:04] Job Status: running\n",
      "[09:34] Job Status: running\n",
      "[10:04] Job Status: running\n",
      "[10:34] Job Status: running\n",
      "[11:05] Job Status: running\n",
      "[11:35] Job Status: running\n",
      "[12:05] Job Status: running\n",
      "[12:35] Job Status: running\n",
      "[13:05] Job Status: running\n",
      "[13:36] Job Status: running\n",
      "[14:06] Job Status: running\n",
      "[14:36] Job Status: running\n",
      "[15:06] Job Status: running\n",
      "[15:36] Job Status: running\n",
      "[16:07] Job Status: running\n",
      "[16:37] Job Status: running\n",
      "[17:07] Job Status: running\n",
      "[17:37] Job Status: running\n",
      "[18:07] Job Status: running\n",
      "[18:43] Job Status: running\n",
      "[19:14] Job Status: running\n",
      "[19:44] Job Status: running\n",
      "[20:14] Job Status: running\n",
      "[20:44] Job Status: running\n",
      "[21:14] Job Status: running\n",
      "[21:44] Job Status: running\n",
      "[22:15] Job Status: running\n",
      "[22:45] Job Status: running\n",
      "[23:15] Job Status: running\n",
      "[23:45] Job Status: running\n",
      "[24:15] Job Status: running\n",
      "[24:46] Job Status: running\n",
      "[25:16] Job Status: running\n",
      "[25:46] Job Status: running\n",
      "[26:16] Job Status: running\n",
      "[26:46] Job Status: running\n",
      "[27:17] Job Status: running\n",
      "[27:47] Job Status: running\n",
      "[28:17] Job Status: running\n",
      "[28:47] Job Status: running\n",
      "[29:17] Job Status: running\n",
      "[29:48] Job Status: running\n",
      "[31:06] Job Status: running\n",
      "[31:36] Job Status: running\n",
      "[32:06] Job Status: running\n",
      "[32:36] Job Status: running\n",
      "[33:07] Job Status: running\n",
      "[33:37] Job Status: running\n",
      "[34:07] Job Status: running\n",
      "[34:37] Job Status: running\n",
      "[35:07] Job Status: running\n",
      "[35:37] Job Status: running\n",
      "[36:08] Job Status: running\n",
      "[36:38] Job Status: running\n",
      "[37:08] Job Status: running\n",
      "[37:38] Job Status: running\n",
      "[38:08] Job Status: running\n",
      "[38:39] Job Status: running\n",
      "[39:09] Job Status: running\n",
      "[39:39] Job Status: running\n",
      "[40:09] Job Status: running\n",
      "[40:39] Job Status: running\n",
      "[41:10] Job Status: running\n",
      "[41:40] Job Status: running\n",
      "[42:10] Job Status: running\n",
      "[42:40] Job Status: running\n",
      "[43:10] Job Status: running\n",
      "[43:40] Job Status: running\n",
      "[44:11] Job Status: running\n",
      "[44:41] Job Status: running\n",
      "[45:11] Job Status: running\n",
      "[45:41] Job Status: running\n",
      "[46:11] Job Status: running\n",
      "[46:42] Job Status: running\n",
      "[47:12] Job Status: running\n",
      "[47:42] Job Status: running\n",
      "[48:12] Job Status: running\n",
      "[48:42] Job Status: running\n",
      "[49:12] Job Status: running\n",
      "[49:43] Job Status: running\n",
      "[50:13] Job Status: running\n",
      "[50:43] Job Status: running\n",
      "[51:13] Job Status: running\n",
      "[51:43] Job Status: running\n",
      "[52:13] Job Status: running\n",
      "[52:44] Job Status: running\n",
      "[53:14] Job Status: running\n",
      "[53:44] Job Status: running\n",
      "[54:14] Job Status: running\n",
      "[54:44] Job Status: running\n",
      "[55:15] Job Status: running\n",
      "[56:05] Job Status: succeeded\n",
      "\n",
      "Job finished with status: succeeded\n",
      "\n",
      "Fine-tuned model created: ft:gpt-3.5-turbo-0125:personal:emoji-v1:CRqb7Ag7\n"
     ]
    }
   ],
   "source": [
    "POLL_INTERVAL = 30  # seconds\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"Monitoring job {job_id}. Polling every {POLL_INTERVAL} seconds...\")\n",
    "\n",
    "while True:\n",
    "    job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    status = job.status\n",
    "\n",
    "    elapsed_time = int(time.time() - start_time)\n",
    "    minutes, seconds = divmod(elapsed_time, 60)\n",
    "\n",
    "    print(f\"[{minutes:02d}:{seconds:02d}] Job Status: {status}\")\n",
    "\n",
    "    if status in [\"succeeded\", \"failed\", \"cancelled\"]:\n",
    "        print(f\"\\nJob finished with status: {status}\")\n",
    "        break\n",
    "\n",
    "    time.sleep(POLL_INTERVAL)\n",
    "\n",
    "# Retrieve the final job details\n",
    "final_job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "fine_tuned_model_id = final_job.fine_tuned_model\n",
    "\n",
    "if fine_tuned_model_id:\n",
    "    print(f\"\\nFine-tuned model created: {fine_tuned_model_id}\")\n",
    "else:\n",
    "    print(\"\\nFine-tuned model ID not found. Check job details below:\")\n",
    "    print(final_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Job Events\n",
    "With the job wrapped up, I take a quick look under the hood by pulling the event stream for this run. I ask the API for up to fifty recent events, then reverse the list so I can read the story in chronological order from the earliest messages to the latest. Each line shows when the event happened, the severity level, and a short message, which makes it easy to spot data validation notes, training phase changes, or any warnings that might explain delays. I keep the whole thing inside a try and except so a transient API hiccup or a permissions snag does not derail the notebook; if fetching fails, I print the error and move on armed with whatever information I already have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching events for job ftjob-m6dEhtrjGqtAFuuKWPuvEkFA...\n",
      "\n",
      "- 1760753005: [info] Step 1665/1707: training loss=0.02\n",
      "- 1760753005: [info] Step 1666/1707: training loss=0.00\n",
      "- 1760753008: [info] Step 1667/1707: training loss=0.00\n",
      "- 1760753008: [info] Step 1668/1707: training loss=0.00\n",
      "- 1760753011: [info] Step 1669/1707: training loss=0.00\n",
      "- 1760753012: [info] Step 1670/1707: training loss=0.61\n",
      "- 1760753015: [info] Step 1671/1707: training loss=0.00\n",
      "- 1760753015: [info] Step 1672/1707: training loss=0.00\n",
      "- 1760753015: [info] Step 1673/1707: training loss=0.00\n",
      "- 1760753018: [info] Step 1674/1707: training loss=0.00\n",
      "- 1760753018: [info] Step 1675/1707: training loss=0.00\n",
      "- 1760753021: [info] Step 1676/1707: training loss=0.05\n",
      "- 1760753021: [info] Step 1677/1707: training loss=2.36\n",
      "- 1760753024: [info] Step 1678/1707: training loss=0.00\n",
      "- 1760753024: [info] Step 1679/1707: training loss=0.00\n",
      "- 1760753027: [info] Step 1680/1707: training loss=0.00\n",
      "- 1760753027: [info] Step 1681/1707: training loss=0.00\n",
      "- 1760753027: [info] Step 1682/1707: training loss=1.60\n",
      "- 1760753033: [info] Step 1683/1707: training loss=2.96\n",
      "- 1760753036: [info] Step 1684/1707: training loss=0.01\n",
      "- 1760753036: [info] Step 1685/1707: training loss=1.72\n",
      "- 1760753039: [info] Step 1686/1707: training loss=0.00\n",
      "- 1760753039: [info] Step 1687/1707: training loss=0.00\n",
      "- 1760753042: [info] Step 1688/1707: training loss=0.01\n",
      "- 1760753042: [info] Step 1689/1707: training loss=0.00\n",
      "- 1760753042: [info] Step 1690/1707: training loss=0.70\n",
      "- 1760753045: [info] Step 1691/1707: training loss=0.00\n",
      "- 1760753046: [info] Step 1692/1707: training loss=0.00\n",
      "- 1760753049: [info] Step 1693/1707: training loss=0.00\n",
      "- 1760753049: [info] Step 1694/1707: training loss=0.65\n",
      "- 1760753049: [info] Step 1695/1707: training loss=0.00\n",
      "- 1760753051: [info] Step 1696/1707: training loss=0.91\n",
      "- 1760753052: [info] Step 1697/1707: training loss=0.00\n",
      "- 1760753055: [info] Step 1698/1707: training loss=0.00\n",
      "- 1760753055: [info] Step 1699/1707: training loss=0.00\n",
      "- 1760753055: [info] Step 1700/1707: training loss=0.00\n",
      "- 1760753058: [info] Step 1701/1707: training loss=4.22\n",
      "- 1760753058: [info] Step 1702/1707: training loss=0.99\n",
      "- 1760753061: [info] Step 1703/1707: training loss=0.00\n",
      "- 1760753061: [info] Step 1704/1707: training loss=4.23\n",
      "- 1760753064: [info] Step 1705/1707: training loss=0.26\n",
      "- 1760753064: [info] Step 1706/1707: training loss=0.00\n",
      "- 1760753067: [info] Step 1707/1707: training loss=0.02\n",
      "- 1760753078: [info] Checkpoint created at step 569\n",
      "- 1760753078: [info] Checkpoint created at step 1138\n",
      "- 1760753078: [info] New fine-tuned model created\n",
      "- 1760753078: [info] Evaluating model against our usage policies\n",
      "- 1760753875: [info] Moderation checks for snapshot ft:gpt-3.5-turbo-0125:personal:emoji-v1:CRqb7Ag7 passed.\n",
      "- 1760753875: [info] Usage policy evaluations completed, model is now enabled for sampling\n",
      "- 1760753882: [info] The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fetching events for job {job_id}...\\n\")\n",
    "try:\n",
    "    # Using the SDK to list events\n",
    "    events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=50)\n",
    "\n",
    "    for event in reversed(list(events.data)):\n",
    "        print(f\"- {event.created_at}: [{event.level}] {event.message}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not fetch events: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Fine-Tuned Model\n",
    "This is the moment of truth. If the job returned a model ID, I run a quick smoke test to make sure the custom model actually answers. I craft a tiny chat with a system rule that forces emoji-only replies and a blunt user prompt to see how the tone is handled, then call the Chat Completions API with a small token budget and print whatever the model says. If there is no model ID, I explain why and skip the test rather than crashing the notebook. This is not a benchmark or a quality evaluation, just a fast sanity check that the fine-tuning pipeline completed and the model can follow the intended style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: ft:gpt-3.5-turbo-0125:personal:emoji-v1:CRqb7Ag7\n",
      "\n",
      "Model Response: (devil)\n"
     ]
    }
   ],
   "source": [
    "if not fine_tuned_model_id:\n",
    "    print(\"Fine-tuned model ID is not available. Cannot run test.\")\n",
    "else:\n",
    "    test_messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You're a chatbot that only responds with emojis!\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"What the hell is going on?\"},\n",
    "    ]\n",
    "\n",
    "    print(f\"Testing model: {fine_tuned_model_id}\")\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=fine_tuned_model_id,\n",
    "        messages=test_messages,\n",
    "        max_tokens=50,\n",
    "    )\n",
    "\n",
    "    response_content = completion.choices[0].message.content\n",
    "    print(f\"\\nModel Response: {response_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "I read this output as the model doing exactly what I trained it to do. The assistant targets in my dataset are parenthesized labels rather than Unicode characters, and across 569 examples there are no true emojis in the assistant outputs, with 349 distinct labels that include `(devil)` appearing multiple times. Given that, the reply `(devil)` is a faithful reproduction of the training style and it correctly maps the word hell to a devil sentiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
